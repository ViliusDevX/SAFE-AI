# Safe AI

**Mission:** Make advanced AI systems transparent, interpretable, and aligned, ***before it’s too late***.

This repository is the public home of my personal mission to fight for AI safety and transparency.  
I’m Vilius, a (almost) 17-year-old with a background in cybersecurity, Python, and AI tools who had an existential wake up call about the dangers of uncontrolled, opaque AI systems.

Here you’ll find:

- **Manifesto** — my statement of principles and goals.
- **Research Hub** — curated resources on AI interpretability and alignment.
- **Guides & Tools** — open source experiments and code to help reveal AI “black boxes.”
- **Roadmap** — a living plan for projects, activism, and collaborations.

The goal is to **push for a world where no powerful AI is deployed without independent review, transparency, and proven alignment**.  
If you share this vision, whether you’re a developer, researcher, policymaker, or just someone who cares - you can join by contributing code, ideas, translations, funding, or advocacy.

**If we actually do something, we *might* still have a chance.**
